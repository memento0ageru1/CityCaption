{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim\n",
    "# from gensim.utils import simple_preprocess\n",
    "# import pandas as pd\n",
    "# import nltk\n",
    "# df=pd.read_csv('/content/drive/MyDrive/街景聚类/0223scene标签.csv')\n",
    "# # df.head(1)\n",
    "# df['s1']=df['captions'].apply(lambda x:x.split(';')[0])\n",
    "\n",
    "# def sent_to_words(sentences):\n",
    "#     for sentence in sentences:\n",
    "#         yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "# data = df.scene.values.tolist()\n",
    "# data_words = list(sent_to_words(data))\n",
    "# print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['truck', 'driving', 'down', 'road', 'under', 'bridge']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import pandas as pd\n",
    "import nltk\n",
    "df=pd.read_csv(r'C:\\OneDriveFile\\OneDrive - whu.edu.cn\\街景抽取标签进行聚类\\数据代码整理\\data\\wuhan_sv_data.csv')\n",
    "# df.head(1)\n",
    "df['s1']=df['captions'].apply(lambda x:x.split(';')[0])\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "data = df.s1.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to D:\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['truck', 'driving', 'road', 'bridge']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "data = df.s1.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #10000 to Dictionary(474 unique tokens: ['bridge', 'driving', 'road', 'truck', 'blue']...)\n",
      "adding document #20000 to Dictionary(545 unique tokens: ['bridge', 'driving', 'road', 'truck', 'blue']...)\n",
      "adding document #30000 to Dictionary(587 unique tokens: ['bridge', 'driving', 'road', 'truck', 'blue']...)\n",
      "adding document #40000 to Dictionary(631 unique tokens: ['bridge', 'driving', 'road', 'truck', 'blue']...)\n",
      "adding document #50000 to Dictionary(652 unique tokens: ['bridge', 'driving', 'road', 'truck', 'blue']...)\n",
      "adding document #60000 to Dictionary(674 unique tokens: ['bridge', 'driving', 'road', 'truck', 'blue']...)\n",
      "adding document #70000 to Dictionary(691 unique tokens: ['bridge', 'driving', 'road', 'truck', 'blue']...)\n",
      "built Dictionary(710 unique tokens: ['bridge', 'driving', 'road', 'truck', 'blue']...) from 78984 documents (total 362754 corpus positions)\n",
      "Dictionary lifecycle event {'msg': \"built Dictionary(710 unique tokens: ['bridge', 'driving', 'road', 'truck', 'blue']...) from 78984 documents (total 362754 corpus positions)\", 'datetime': '2022-03-08T15:28:48.285321', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1)]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using symmetric alpha at 0.08333333333333333\n",
      "using symmetric eta at 0.08333333333333333\n",
      "using serial LDA version on this node\n",
      "running online LDA training, 12 topics, 1 passes over the supplied corpus of 78984 documents, updating every 14000 documents, evaluating every ~78984 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "training LDA model using 7 processes\n",
      "PROGRESS: pass 0, dispatched chunk #0 = documents up to #2000/78984, outstanding queue size 1\n",
      "PROGRESS: pass 0, dispatched chunk #1 = documents up to #4000/78984, outstanding queue size 2\n",
      "PROGRESS: pass 0, dispatched chunk #2 = documents up to #6000/78984, outstanding queue size 3\n",
      "PROGRESS: pass 0, dispatched chunk #3 = documents up to #8000/78984, outstanding queue size 4\n",
      "PROGRESS: pass 0, dispatched chunk #4 = documents up to #10000/78984, outstanding queue size 5\n",
      "PROGRESS: pass 0, dispatched chunk #5 = documents up to #12000/78984, outstanding queue size 6\n",
      "PROGRESS: pass 0, dispatched chunk #6 = documents up to #14000/78984, outstanding queue size 7\n",
      "PROGRESS: pass 0, dispatched chunk #7 = documents up to #16000/78984, outstanding queue size 8\n",
      "PROGRESS: pass 0, dispatched chunk #8 = documents up to #18000/78984, outstanding queue size 9\n",
      "PROGRESS: pass 0, dispatched chunk #9 = documents up to #20000/78984, outstanding queue size 10\n",
      "PROGRESS: pass 0, dispatched chunk #10 = documents up to #22000/78984, outstanding queue size 11\n",
      "PROGRESS: pass 0, dispatched chunk #11 = documents up to #24000/78984, outstanding queue size 12\n",
      "PROGRESS: pass 0, dispatched chunk #12 = documents up to #26000/78984, outstanding queue size 13\n",
      "PROGRESS: pass 0, dispatched chunk #13 = documents up to #28000/78984, outstanding queue size 14\n",
      "PROGRESS: pass 0, dispatched chunk #14 = documents up to #30000/78984, outstanding queue size 15\n",
      "PROGRESS: pass 0, dispatched chunk #15 = documents up to #32000/78984, outstanding queue size 16\n",
      "PROGRESS: pass 0, dispatched chunk #16 = documents up to #34000/78984, outstanding queue size 17\n",
      "PROGRESS: pass 0, dispatched chunk #17 = documents up to #36000/78984, outstanding queue size 18\n",
      "PROGRESS: pass 0, dispatched chunk #18 = documents up to #38000/78984, outstanding queue size 19\n",
      "PROGRESS: pass 0, dispatched chunk #19 = documents up to #40000/78984, outstanding queue size 20\n",
      "PROGRESS: pass 0, dispatched chunk #20 = documents up to #42000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #21 = documents up to #44000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #22 = documents up to #46000/78984, outstanding queue size 22\n",
      "PROGRESS: pass 0, dispatched chunk #23 = documents up to #48000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #24 = documents up to #50000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #25 = documents up to #52000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #26 = documents up to #54000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #27 = documents up to #56000/78984, outstanding queue size 22\n",
      "merging changes from 14000 documents into a model of 78984 documents\n",
      "topic #10 (0.083): 0.142*\"street\" + 0.099*\"driving\" + 0.078*\"cars\" + 0.050*\"buildings\" + 0.050*\"city\" + 0.046*\"next\" + 0.036*\"tall\" + 0.034*\"car\" + 0.032*\"building\" + 0.030*\"group\"\n",
      "topic #5 (0.083): 0.083*\"street\" + 0.071*\"front\" + 0.063*\"parked\" + 0.059*\"building\" + 0.051*\"cars\" + 0.050*\"buildings\" + 0.042*\"tall\" + 0.037*\"city\" + 0.036*\"car\" + 0.035*\"group\"\n",
      "topic #6 (0.083): 0.108*\"parked\" + 0.072*\"building\" + 0.069*\"side\" + 0.065*\"road\" + 0.057*\"street\" + 0.049*\"front\" + 0.038*\"car\" + 0.037*\"white\" + 0.035*\"truck\" + 0.031*\"cars\"\n",
      "topic #7 (0.083): 0.091*\"street\" + 0.076*\"road\" + 0.043*\"city\" + 0.042*\"truck\" + 0.039*\"driving\" + 0.036*\"parked\" + 0.031*\"trees\" + 0.030*\"side\" + 0.028*\"next\" + 0.028*\"dirt\"\n",
      "topic #9 (0.083): 0.105*\"street\" + 0.049*\"building\" + 0.044*\"driving\" + 0.044*\"group\" + 0.035*\"people\" + 0.035*\"road\" + 0.032*\"walking\" + 0.032*\"side\" + 0.031*\"cars\" + 0.029*\"bridge\"\n",
      "topic diff=11.167812, rho=1.000000\n",
      "PROGRESS: pass 0, dispatched chunk #28 = documents up to #58000/78984, outstanding queue size 22\n",
      "PROGRESS: pass 0, dispatched chunk #29 = documents up to #60000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #30 = documents up to #62000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #31 = documents up to #64000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #32 = documents up to #66000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #33 = documents up to #68000/78984, outstanding queue size 21\n",
      "merging changes from 14000 documents into a model of 78984 documents\n",
      "topic #9 (0.083): 0.097*\"street\" + 0.049*\"building\" + 0.045*\"group\" + 0.039*\"people\" + 0.038*\"walking\" + 0.036*\"driving\" + 0.034*\"bridge\" + 0.033*\"road\" + 0.031*\"side\" + 0.027*\"view\"\n",
      "topic #1 (0.083): 0.126*\"street\" + 0.083*\"city\" + 0.061*\"buildings\" + 0.058*\"building\" + 0.037*\"tall\" + 0.032*\"traffic\" + 0.030*\"background\" + 0.030*\"driving\" + 0.029*\"filled\" + 0.027*\"empty\"\n",
      "topic #4 (0.083): 0.080*\"parked\" + 0.069*\"road\" + 0.062*\"car\" + 0.061*\"side\" + 0.053*\"street\" + 0.049*\"front\" + 0.049*\"building\" + 0.035*\"cars\" + 0.035*\"city\" + 0.026*\"buildings\"\n",
      "topic #8 (0.083): 0.081*\"cars\" + 0.070*\"parked\" + 0.063*\"street\" + 0.058*\"group\" + 0.042*\"building\" + 0.041*\"lot\" + 0.038*\"couple\" + 0.037*\"parking\" + 0.033*\"wall\" + 0.031*\"people\"\n",
      "topic #6 (0.083): 0.110*\"parked\" + 0.074*\"building\" + 0.070*\"side\" + 0.067*\"road\" + 0.052*\"street\" + 0.049*\"front\" + 0.037*\"car\" + 0.037*\"white\" + 0.036*\"truck\" + 0.030*\"cars\"\n",
      "topic diff=1.050365, rho=0.353553\n",
      "PROGRESS: pass 0, dispatched chunk #34 = documents up to #70000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #35 = documents up to #72000/78984, outstanding queue size 22\n",
      "PROGRESS: pass 0, dispatched chunk #36 = documents up to #74000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #37 = documents up to #76000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #38 = documents up to #78000/78984, outstanding queue size 21\n",
      "PROGRESS: pass 0, dispatched chunk #39 = documents up to #78984/78984, outstanding queue size 21\n",
      "merging changes from 14000 documents into a model of 78984 documents\n",
      "topic #5 (0.083): 0.090*\"front\" + 0.066*\"parked\" + 0.066*\"street\" + 0.066*\"building\" + 0.043*\"cars\" + 0.041*\"buildings\" + 0.039*\"store\" + 0.034*\"tall\" + 0.032*\"car\" + 0.031*\"group\"\n",
      "topic #11 (0.083): 0.134*\"street\" + 0.075*\"cars\" + 0.069*\"city\" + 0.063*\"group\" + 0.051*\"people\" + 0.045*\"parked\" + 0.036*\"walking\" + 0.028*\"sitting\" + 0.026*\"side\" + 0.024*\"building\"\n",
      "topic #1 (0.083): 0.129*\"street\" + 0.087*\"city\" + 0.069*\"buildings\" + 0.058*\"building\" + 0.041*\"tall\" + 0.038*\"traffic\" + 0.036*\"filled\" + 0.035*\"background\" + 0.029*\"empty\" + 0.023*\"driving\"\n",
      "topic #7 (0.083): 0.095*\"road\" + 0.070*\"street\" + 0.049*\"trees\" + 0.043*\"dirt\" + 0.041*\"truck\" + 0.033*\"driving\" + 0.032*\"city\" + 0.031*\"next\" + 0.030*\"parked\" + 0.029*\"side\"\n",
      "topic #6 (0.083): 0.121*\"parked\" + 0.081*\"side\" + 0.078*\"building\" + 0.074*\"road\" + 0.052*\"front\" + 0.047*\"street\" + 0.042*\"car\" + 0.037*\"truck\" + 0.037*\"white\" + 0.031*\"cars\"\n",
      "topic diff=0.395268, rho=0.258199\n",
      "-4.354 per-word bound, 20.4 perplexity estimate based on a held-out corpus of 984 documents with 4590 words\n",
      "merging changes from 14000 documents into a model of 78984 documents\n",
      "topic #6 (0.083): 0.134*\"parked\" + 0.091*\"side\" + 0.081*\"road\" + 0.080*\"building\" + 0.055*\"front\" + 0.046*\"car\" + 0.043*\"street\" + 0.040*\"white\" + 0.040*\"truck\" + 0.036*\"cars\"\n",
      "topic #9 (0.083): 0.079*\"street\" + 0.065*\"bridge\" + 0.053*\"group\" + 0.051*\"people\" + 0.048*\"walking\" + 0.040*\"building\" + 0.034*\"view\" + 0.030*\"water\" + 0.030*\"driving\" + 0.030*\"road\"\n",
      "topic #0 (0.083): 0.166*\"street\" + 0.079*\"city\" + 0.047*\"view\" + 0.039*\"buildings\" + 0.037*\"person\" + 0.032*\"riding\" + 0.030*\"building\" + 0.030*\"walking\" + 0.028*\"next\" + 0.028*\"sidewalk\"\n",
      "topic #8 (0.083): 0.069*\"cars\" + 0.067*\"parked\" + 0.064*\"lot\" + 0.061*\"parking\" + 0.048*\"building\" + 0.048*\"group\" + 0.045*\"street\" + 0.043*\"couple\" + 0.041*\"wall\" + 0.029*\"people\"\n",
      "topic #1 (0.083): 0.130*\"street\" + 0.093*\"city\" + 0.076*\"buildings\" + 0.052*\"building\" + 0.049*\"traffic\" + 0.047*\"tall\" + 0.046*\"filled\" + 0.042*\"background\" + 0.029*\"empty\" + 0.025*\"large\"\n",
      "topic diff=0.129689, rho=0.213201\n",
      "-4.279 per-word bound, 19.4 perplexity estimate based on a held-out corpus of 984 documents with 4590 words\n",
      "merging changes from 14984 documents into a model of 78984 documents\n",
      "topic #4 (0.083): 0.085*\"road\" + 0.083*\"parked\" + 0.073*\"side\" + 0.068*\"car\" + 0.052*\"building\" + 0.047*\"front\" + 0.046*\"street\" + 0.033*\"cars\" + 0.033*\"large\" + 0.032*\"long\"\n",
      "topic #0 (0.083): 0.170*\"street\" + 0.081*\"city\" + 0.046*\"view\" + 0.043*\"person\" + 0.038*\"riding\" + 0.037*\"buildings\" + 0.032*\"walking\" + 0.029*\"building\" + 0.028*\"sidewalk\" + 0.027*\"next\"\n",
      "topic #2 (0.083): 0.060*\"building\" + 0.056*\"car\" + 0.048*\"street\" + 0.042*\"driving\" + 0.041*\"white\" + 0.040*\"next\" + 0.035*\"blue\" + 0.032*\"tree\" + 0.032*\"sidewalk\" + 0.031*\"sitting\"\n",
      "topic #6 (0.083): 0.151*\"parked\" + 0.103*\"side\" + 0.084*\"road\" + 0.080*\"building\" + 0.060*\"front\" + 0.054*\"car\" + 0.043*\"white\" + 0.042*\"street\" + 0.041*\"cars\" + 0.040*\"truck\"\n",
      "topic #11 (0.083): 0.156*\"street\" + 0.089*\"cars\" + 0.081*\"group\" + 0.071*\"city\" + 0.066*\"people\" + 0.047*\"parked\" + 0.044*\"walking\" + 0.036*\"sitting\" + 0.022*\"side\" + 0.022*\"couple\"\n",
      "topic diff=0.110256, rho=0.185695\n",
      "-4.212 per-word bound, 18.5 perplexity estimate based on a held-out corpus of 984 documents with 4590 words\n",
      "merging changes from 8000 documents into a model of 78984 documents\n",
      "topic #2 (0.083): 0.061*\"building\" + 0.048*\"tree\" + 0.045*\"car\" + 0.043*\"next\" + 0.041*\"street\" + 0.041*\"middle\" + 0.040*\"white\" + 0.040*\"sidewalk\" + 0.037*\"sitting\" + 0.034*\"driving\"\n",
      "topic #4 (0.083): 0.087*\"road\" + 0.080*\"parked\" + 0.075*\"side\" + 0.066*\"car\" + 0.056*\"building\" + 0.047*\"front\" + 0.045*\"street\" + 0.038*\"large\" + 0.035*\"long\" + 0.032*\"cars\"\n",
      "topic #9 (0.083): 0.074*\"people\" + 0.069*\"walking\" + 0.066*\"group\" + 0.066*\"street\" + 0.063*\"bridge\" + 0.053*\"sidewalk\" + 0.037*\"building\" + 0.032*\"view\" + 0.031*\"water\" + 0.026*\"body\"\n",
      "topic #8 (0.083): 0.072*\"lot\" + 0.068*\"parking\" + 0.062*\"parked\" + 0.059*\"cars\" + 0.055*\"building\" + 0.050*\"couple\" + 0.049*\"wall\" + 0.040*\"group\" + 0.035*\"street\" + 0.027*\"people\"\n",
      "topic #5 (0.083): 0.130*\"front\" + 0.079*\"parked\" + 0.074*\"building\" + 0.068*\"store\" + 0.049*\"street\" + 0.043*\"cars\" + 0.032*\"car\" + 0.031*\"group\" + 0.029*\"buildings\" + 0.027*\"tall\"\n",
      "topic diff=0.103682, rho=0.165539\n",
      "-4.176 per-word bound, 18.1 perplexity estimate based on a held-out corpus of 984 documents with 4590 words\n",
      "LdaMulticore lifecycle event {'msg': 'trained LdaModel(num_terms=710, num_topics=12, decay=0.5, chunksize=2000) in 11.02s', 'datetime': '2022-03-08T15:29:24.595471', 'gensim': '4.1.2', 'python': '3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "topic #0 (0.083): 0.171*\"street\" + 0.081*\"city\" + 0.049*\"person\" + 0.046*\"view\" + 0.041*\"riding\" + 0.035*\"buildings\" + 0.034*\"walking\" + 0.032*\"sidewalk\" + 0.030*\"building\" + 0.027*\"next\"\n",
      "topic #1 (0.083): 0.140*\"street\" + 0.104*\"city\" + 0.087*\"buildings\" + 0.058*\"traffic\" + 0.058*\"filled\" + 0.055*\"tall\" + 0.048*\"building\" + 0.048*\"background\" + 0.028*\"lots\" + 0.028*\"empty\"\n",
      "topic #2 (0.083): 0.061*\"building\" + 0.048*\"tree\" + 0.045*\"car\" + 0.043*\"next\" + 0.041*\"street\" + 0.041*\"middle\" + 0.040*\"white\" + 0.040*\"sidewalk\" + 0.037*\"sitting\" + 0.034*\"driving\"\n",
      "topic #3 (0.083): 0.166*\"street\" + 0.127*\"city\" + 0.088*\"view\" + 0.048*\"car\" + 0.043*\"driving\" + 0.029*\"building\" + 0.028*\"white\" + 0.028*\"buildings\" + 0.027*\"across\" + 0.022*\"skyline\"\n",
      "topic #4 (0.083): 0.087*\"road\" + 0.080*\"parked\" + 0.075*\"side\" + 0.066*\"car\" + 0.056*\"building\" + 0.047*\"front\" + 0.045*\"street\" + 0.038*\"large\" + 0.035*\"long\" + 0.032*\"cars\"\n",
      "topic #5 (0.083): 0.130*\"front\" + 0.079*\"parked\" + 0.074*\"building\" + 0.068*\"store\" + 0.049*\"street\" + 0.043*\"cars\" + 0.032*\"car\" + 0.031*\"group\" + 0.029*\"buildings\" + 0.027*\"tall\"\n",
      "topic #6 (0.083): 0.157*\"parked\" + 0.112*\"side\" + 0.090*\"road\" + 0.079*\"building\" + 0.059*\"front\" + 0.058*\"car\" + 0.042*\"white\" + 0.042*\"street\" + 0.042*\"cars\" + 0.040*\"truck\"\n",
      "topic #7 (0.083): 0.104*\"road\" + 0.073*\"trees\" + 0.053*\"street\" + 0.043*\"dirt\" + 0.039*\"truck\" + 0.036*\"next\" + 0.034*\"driving\" + 0.023*\"forest\" + 0.023*\"fence\" + 0.023*\"side\"\n",
      "topic #8 (0.083): 0.072*\"lot\" + 0.068*\"parking\" + 0.062*\"parked\" + 0.059*\"cars\" + 0.055*\"building\" + 0.050*\"couple\" + 0.049*\"wall\" + 0.040*\"group\" + 0.035*\"street\" + 0.027*\"people\"\n",
      "topic #9 (0.083): 0.074*\"people\" + 0.069*\"walking\" + 0.066*\"group\" + 0.066*\"street\" + 0.063*\"bridge\" + 0.053*\"sidewalk\" + 0.037*\"building\" + 0.032*\"view\" + 0.031*\"water\" + 0.026*\"body\"\n",
      "topic #10 (0.083): 0.150*\"driving\" + 0.144*\"street\" + 0.087*\"cars\" + 0.063*\"buildings\" + 0.059*\"next\" + 0.051*\"tall\" + 0.050*\"city\" + 0.048*\"car\" + 0.035*\"group\" + 0.025*\"bus\"\n",
      "topic #11 (0.083): 0.160*\"street\" + 0.088*\"cars\" + 0.086*\"group\" + 0.074*\"people\" + 0.068*\"city\" + 0.049*\"walking\" + 0.044*\"parked\" + 0.040*\"sitting\" + 0.024*\"couple\" + 0.021*\"side\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.171*\"street\" + 0.081*\"city\" + 0.049*\"person\" + 0.046*\"view\" + '\n",
      "  '0.041*\"riding\" + 0.035*\"buildings\" + 0.034*\"walking\" + 0.032*\"sidewalk\" + '\n",
      "  '0.030*\"building\" + 0.027*\"next\"'),\n",
      " (1,\n",
      "  '0.140*\"street\" + 0.104*\"city\" + 0.087*\"buildings\" + 0.058*\"traffic\" + '\n",
      "  '0.058*\"filled\" + 0.055*\"tall\" + 0.048*\"building\" + 0.048*\"background\" + '\n",
      "  '0.028*\"lots\" + 0.028*\"empty\"'),\n",
      " (2,\n",
      "  '0.061*\"building\" + 0.048*\"tree\" + 0.045*\"car\" + 0.043*\"next\" + '\n",
      "  '0.041*\"street\" + 0.041*\"middle\" + 0.040*\"white\" + 0.040*\"sidewalk\" + '\n",
      "  '0.037*\"sitting\" + 0.034*\"driving\"'),\n",
      " (3,\n",
      "  '0.166*\"street\" + 0.127*\"city\" + 0.088*\"view\" + 0.048*\"car\" + '\n",
      "  '0.043*\"driving\" + 0.029*\"building\" + 0.028*\"white\" + 0.028*\"buildings\" + '\n",
      "  '0.027*\"across\" + 0.022*\"skyline\"'),\n",
      " (4,\n",
      "  '0.087*\"road\" + 0.080*\"parked\" + 0.075*\"side\" + 0.066*\"car\" + '\n",
      "  '0.056*\"building\" + 0.047*\"front\" + 0.045*\"street\" + 0.038*\"large\" + '\n",
      "  '0.035*\"long\" + 0.032*\"cars\"'),\n",
      " (5,\n",
      "  '0.130*\"front\" + 0.079*\"parked\" + 0.074*\"building\" + 0.068*\"store\" + '\n",
      "  '0.049*\"street\" + 0.043*\"cars\" + 0.032*\"car\" + 0.031*\"group\" + '\n",
      "  '0.029*\"buildings\" + 0.027*\"tall\"'),\n",
      " (6,\n",
      "  '0.157*\"parked\" + 0.112*\"side\" + 0.090*\"road\" + 0.079*\"building\" + '\n",
      "  '0.059*\"front\" + 0.058*\"car\" + 0.042*\"white\" + 0.042*\"street\" + 0.042*\"cars\" '\n",
      "  '+ 0.040*\"truck\"'),\n",
      " (7,\n",
      "  '0.104*\"road\" + 0.073*\"trees\" + 0.053*\"street\" + 0.043*\"dirt\" + '\n",
      "  '0.039*\"truck\" + 0.036*\"next\" + 0.034*\"driving\" + 0.023*\"forest\" + '\n",
      "  '0.023*\"fence\" + 0.023*\"side\"'),\n",
      " (8,\n",
      "  '0.072*\"lot\" + 0.068*\"parking\" + 0.062*\"parked\" + 0.059*\"cars\" + '\n",
      "  '0.055*\"building\" + 0.050*\"couple\" + 0.049*\"wall\" + 0.040*\"group\" + '\n",
      "  '0.035*\"street\" + 0.027*\"people\"'),\n",
      " (9,\n",
      "  '0.074*\"people\" + 0.069*\"walking\" + 0.066*\"group\" + 0.066*\"street\" + '\n",
      "  '0.063*\"bridge\" + 0.053*\"sidewalk\" + 0.037*\"building\" + 0.032*\"view\" + '\n",
      "  '0.031*\"water\" + 0.026*\"body\"'),\n",
      " (10,\n",
      "  '0.150*\"driving\" + 0.144*\"street\" + 0.087*\"cars\" + 0.063*\"buildings\" + '\n",
      "  '0.059*\"next\" + 0.051*\"tall\" + 0.050*\"city\" + 0.048*\"car\" + 0.035*\"group\" + '\n",
      "  '0.025*\"bus\"'),\n",
      " (11,\n",
      "  '0.160*\"street\" + 0.088*\"cars\" + 0.086*\"group\" + 0.074*\"people\" + '\n",
      "  '0.068*\"city\" + 0.049*\"walking\" + 0.044*\"parked\" + 0.040*\"sitting\" + '\n",
      "  '0.024*\"couple\" + 0.021*\"side\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# number of topics\n",
    "num_topics = 12\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: pyLDAvis in c:\\programdata\\anaconda3\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.6.2)\n",
      "Requirement already satisfied: sklearn in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.0)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.21.2)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (0.24.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (60.9.3)\n",
      "Requirement already satisfied: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (4.1.2)\n",
      "Requirement already satisfied: funcy in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.16)\n",
      "Requirement already satisfied: numexpr in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from pyLDAvis) (1.0.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (0.29.23)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->pyLDAvis) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# # import pyLDAvis.gensim\n",
    "# import pickle \n",
    "# import pyLDAvis.gensim_models as gensimvis\n",
    "# import pyLDAvis\n",
    "# # Visualize the topics\n",
    "\n",
    "# pyLDAvis.enable_notebook()\n",
    "# # lda_viz = gensimvis.prepare(ldamodel, corpus, dictionary)\n",
    "\n",
    "# LDAvis_data_filepath = os.path.join('./results/ldavis_prepared_'+str(num_topics))\n",
    "# # # this is a bit time consuming - make the if statement True\n",
    "# # # if you want to execute visualization prep yourself\n",
    "# if 1 == 1:\n",
    "#     LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "#     with open(LDAvis_data_filepath, 'wb') as f:\n",
    "#         pickle.dump(LDAvis_prepared, f)\n",
    "# # load the pre-prepared pyLDAvis data from disk\n",
    "# with open(LDAvis_data_filepath, 'rb') as f:\n",
    "#     LDAvis_prepared = pickle.load(f)\n",
    "# pyLDAvis.save_html(LDAvis_prepared, './results/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "# LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim\n",
    "# data = pyLDAvis.sklearn.prepare(lda_model, doc_term_matrix, vectorizer)\n",
    "# #让可视化可以在notebook内显示\n",
    "# pyLDAvis.display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "ldadatas=[(0,\n",
    "  '0.171*\"street\" + 0.081*\"city\" + 0.049*\"person\" + 0.046*\"view\" + '\n",
    "  '0.041*\"riding\" + 0.035*\"buildings\" + 0.034*\"walking\" + 0.032*\"sidewalk\" + '\n",
    "  '0.030*\"building\" + 0.027*\"next\"'),\n",
    " (1,\n",
    "  '0.140*\"street\" + 0.104*\"city\" + 0.087*\"buildings\" + 0.058*\"traffic\" + '\n",
    "  '0.058*\"filled\" + 0.055*\"tall\" + 0.048*\"building\" + 0.048*\"background\" + '\n",
    "  '0.028*\"lots\" + 0.028*\"empty\"'),\n",
    " (2,\n",
    "  '0.061*\"building\" + 0.048*\"tree\" + 0.045*\"car\" + 0.043*\"next\" + '\n",
    "  '0.041*\"street\" + 0.041*\"middle\" + 0.040*\"white\" + 0.040*\"sidewalk\" + '\n",
    "  '0.037*\"sitting\" + 0.034*\"driving\"'),\n",
    " (3,\n",
    "  '0.166*\"street\" + 0.127*\"city\" + 0.088*\"view\" + 0.048*\"car\" + '\n",
    "  '0.043*\"driving\" + 0.029*\"building\" + 0.028*\"white\" + 0.028*\"buildings\" + '\n",
    "  '0.027*\"across\" + 0.022*\"skyline\"'),\n",
    " (4,\n",
    "  '0.087*\"road\" + 0.080*\"parked\" + 0.075*\"side\" + 0.066*\"car\" + '\n",
    "  '0.056*\"building\" + 0.047*\"front\" + 0.045*\"street\" + 0.038*\"large\" + '\n",
    "  '0.035*\"long\" + 0.032*\"cars\"'),\n",
    " (5,\n",
    "  '0.130*\"front\" + 0.079*\"parked\" + 0.074*\"building\" + 0.068*\"store\" + '\n",
    "  '0.049*\"street\" + 0.043*\"cars\" + 0.032*\"car\" + 0.031*\"group\" + '\n",
    "  '0.029*\"buildings\" + 0.027*\"tall\"'),\n",
    " (6,\n",
    "  '0.157*\"parked\" + 0.112*\"side\" + 0.090*\"road\" + 0.079*\"building\" + '\n",
    "  '0.059*\"front\" + 0.058*\"car\" + 0.042*\"white\" + 0.042*\"street\" + 0.042*\"cars\" '\n",
    "  '+ 0.040*\"truck\"'),\n",
    " (7,\n",
    "  '0.104*\"road\" + 0.073*\"trees\" + 0.053*\"street\" + 0.043*\"dirt\" + '\n",
    "  '0.039*\"truck\" + 0.036*\"next\" + 0.034*\"driving\" + 0.023*\"forest\" + '\n",
    "  '0.023*\"fence\" + 0.023*\"side\"'),\n",
    " (8,\n",
    "  '0.072*\"lot\" + 0.068*\"parking\" + 0.062*\"parked\" + 0.059*\"cars\" + '\n",
    "  '0.055*\"building\" + 0.050*\"couple\" + 0.049*\"wall\" + 0.040*\"group\" + '\n",
    "  '0.035*\"street\" + 0.027*\"people\"'),\n",
    " (9,\n",
    "  '0.074*\"people\" + 0.069*\"walking\" + 0.066*\"group\" + 0.066*\"street\" + '\n",
    "  '0.063*\"bridge\" + 0.053*\"sidewalk\" + 0.037*\"building\" + 0.032*\"view\" + '\n",
    "  '0.031*\"water\" + 0.026*\"body\"'),\n",
    " (10,\n",
    "  '0.150*\"driving\" + 0.144*\"street\" + 0.087*\"cars\" + 0.063*\"buildings\" + '\n",
    "  '0.059*\"next\" + 0.051*\"tall\" + 0.050*\"city\" + 0.048*\"car\" + 0.035*\"group\" + '\n",
    "  '0.025*\"bus\"'),\n",
    " (11,\n",
    "  '0.160*\"street\" + 0.088*\"cars\" + 0.086*\"group\" + 0.074*\"people\" + '\n",
    "  '0.068*\"city\" + 0.049*\"walking\" + 0.044*\"parked\" + 0.040*\"sitting\" + '\n",
    "  '0.024*\"couple\" + 0.021*\"side\"')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "cols=['Topic0','Topic1','Topic2',\n",
    "'Topic3','Topic4','Topic5','Topic6','Topic7'\n",
    ",'Topic8','Topic9','Topic10','Topic11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# cols.index('Topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "tables={}\n",
    "for col in cols:\n",
    "    index=cols.index(col)\n",
    "    tables[col]=[]\n",
    "    # print(ldadatas[index][1].split('+'))\n",
    "    for j in ldadatas[index][1].split('+'):\n",
    "            tmp=j.split('*')\n",
    "            tables[col].append(tmp[1])\n",
    "            tables[col].append(tmp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(tables).to_csv('LDA.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div id=f7de60ec-991e-4035-9534-5cb776526462 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">Open in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('f7de60ec-991e-4035-9534-5cb776526462').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "      <th>Topic10</th>\n",
       "      <th>Topic11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"street\"</td>\n",
       "      <td>\"street\"</td>\n",
       "      <td>\"building\"</td>\n",
       "      <td>\"street\"</td>\n",
       "      <td>\"road\"</td>\n",
       "      <td>\"front\"</td>\n",
       "      <td>\"parked\"</td>\n",
       "      <td>\"road\"</td>\n",
       "      <td>\"lot\"</td>\n",
       "      <td>\"people\"</td>\n",
       "      <td>\"driving\"</td>\n",
       "      <td>\"street\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"city\"</td>\n",
       "      <td>\"city\"</td>\n",
       "      <td>\"tree\"</td>\n",
       "      <td>\"city\"</td>\n",
       "      <td>\"parked\"</td>\n",
       "      <td>\"parked\"</td>\n",
       "      <td>\"side\"</td>\n",
       "      <td>\"trees\"</td>\n",
       "      <td>\"parking\"</td>\n",
       "      <td>\"walking\"</td>\n",
       "      <td>\"street\"</td>\n",
       "      <td>\"cars\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"person\"</td>\n",
       "      <td>\"buildings\"</td>\n",
       "      <td>\"car\"</td>\n",
       "      <td>\"view\"</td>\n",
       "      <td>\"side\"</td>\n",
       "      <td>\"building\"</td>\n",
       "      <td>\"road\"</td>\n",
       "      <td>\"street\"</td>\n",
       "      <td>\"parked\"</td>\n",
       "      <td>\"group\"</td>\n",
       "      <td>\"cars\"</td>\n",
       "      <td>\"group\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "      Topic0        Topic1       Topic2     Topic3     Topic4       Topic5  \\\n",
       "0  \"street\"      \"street\"   \"building\"   \"street\"     \"road\"      \"front\"    \n",
       "1      0.171         0.140        0.061      0.166      0.087        0.130   \n",
       "2    \"city\"        \"city\"       \"tree\"     \"city\"   \"parked\"     \"parked\"    \n",
       "3      0.081         0.104        0.048      0.127      0.080        0.079   \n",
       "4  \"person\"   \"buildings\"        \"car\"     \"view\"     \"side\"   \"building\"    \n",
       "\n",
       "      Topic6     Topic7      Topic8      Topic9     Topic10    Topic11  \n",
       "0  \"parked\"     \"road\"       \"lot\"    \"people\"   \"driving\"   \"street\"   \n",
       "1      0.157      0.104       0.072       0.074       0.150      0.160  \n",
       "2    \"side\"    \"trees\"   \"parking\"   \"walking\"    \"street\"     \"cars\"   \n",
       "3      0.112      0.073       0.068       0.069       0.144      0.088  \n",
       "4    \"road\"   \"street\"    \"parked\"     \"group\"      \"cars\"    \"group\"   "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tables).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
